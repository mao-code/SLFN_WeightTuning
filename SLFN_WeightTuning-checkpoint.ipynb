{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/mao-code/SLFN_WeightTuning/blob/main/SLFN_WeightTuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "L22uCWtuTx9i"
   },
   "source": [
    "# This is based on the HW3 of New Learning Algorithm class.\n",
    "<img \n",
    "width=\"500px\"\n",
    "src=\"https://lh3.googleusercontent.com/fife/APg5EOZwrOY0oLYi8YBH38hc_wuinI82mVPRcphGYdR72lxn9aZISGLKs1_OLCXGPF90SVd3hpzHRq9MCxgvCq6IGSyv2winW34Qj16nBvYEddYIvwzQ6hYaWH1kAgVXnfp8FE_e5beZTKDxXmK6dfLwrrYj-G1POJSfaU-Q7VCM1392hTfOqSsS8ZQQQhgV7cYh9mWDVwnhNcTE3qRoqjX_8FceEgiQYUurcNysmEsiGgnB7NkFzoyulDWTYXqBxjJU5T1lMvWCOIliO3lnfcUZIQ24dPj2RnLge95p4axVNBwTq7ZY8BsM0S0FrnBe_fzEY6Nm6Qbl24RXPQXUuP0S7SbIgz1BEkbvjzB5AY9r3o9GUS9Bk5idLqULNOZq9or9onL5Z8O2C_Tkwx1s660x3twZgeF4m3BUPBpjSjmckdCBZFCBeIM-OyG45FJJ7pcRz1V_OPUouQHLWbgi70vGY6BiOBpZcR39Agq_XRNAH5ZTHemKJN9Vz1lbd_FAAldOfdINCM0JJoh_RWvOYuJYO_XolnatONqvsQBxGRwLD-6J_fdLOCec5G8CA42xfs1ycM5mNcc24bVG8Q4dyuetbEF2jJ0qahu1LplQY4YM2rklkcWqAeXm0Qu119gd0lZBhucXDn5lamLXBA5h1xTeFXVsgKuW75hElDjIbBjGt2mL-qIMq1Kw2t0uilsVQhSLv6ILo8eYtOWpvXO2aqmfRPpGcVv1mr0mfILRTNr6VTuLMSVaLFGX0ptBGfLn96xo5KDZPQid29oWQZnWvW-cw4OMzH43i-kqcRQOxT0PlXKLbqcCDFj8Bxb2ccD4xpcQQFb6yb62bMHTDrYd5BcxT9HpHJ5ZtHDI8sEPIOFeP8RtvxURLLKWC2vLRk46U6EkgvMtGteTA_aK07mmY0i1JOLElewJF3lP-5E6r0crBaFXO8v8tTSI6Ps4GL3d3Dkil0Q9NMua0n3piM-J2vg1te6e3QBhD0EwAP_Gj7EQ8EgAARnjyLMOG9QoQJb06PYbex_nvvXye5kIvoG-B_538XUjIMVGiAiDyVDnydMDPtaB6ZD4f0EK3t5DZ81IMjpYvnuDycm9EQ0OsR6jlJe23eBAm63ECsDgJo5rUOYldTFOnE4vtaP4T30ELhGCz_ti8hXKAe7Bu1-zUFvc131lHC0SJUAitxLQLc0GjO1t2nRvNXV1Yk1qKzL68aHzGKGR8L6OpMX7qAQ2sp25POhw2l4s0MKG3nPn-e9FaLvg4TgOQj-sw-eqGCvTf834tzI0ldJzSIHWpmWKPAMDR5wKVVWDm2lMIgGbQE28-LajH1FR9-qKqsFqVSrmmtvUYBQVMhwLS2_yQwtjBQzv51Rxa0PCJViFER9ZCgNaBG5EUcMrepiANCuBAXy_Fc64pbHGOD4_7aaYSgT-n53ql_3mqo0FtTDzAyeIdAvP08ib_0pH9jraUiFTw8CzAk_yNRWbM4zwDLzpHASFpFZRT6mISWCUVPQcrqSSMGDirtoUXej0qtB0yZESGJbsXweATfx1GrECWLRH25aHLxasYmRK_-ShPfl6INC6yYqEr5dG5AvFY0MH2ihXmZNxFnZPdFuWoVA=w2992-h1654\" alt=\"HW3\"></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "IiKWSK4pP5zb"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4mooD8iHY0fn"
   },
   "source": [
    "## Setup Seed\n",
    "在深度學習中，許多操作都涉及到隨機性，例如權重初始化、dropout、數據增強等。這些操作在沒有指定隨機種子的情況下，每次運行時都會生成不同的隨機數序列，從而導致不同的結果。而通過設定隨機種子，可以使得每次生成的隨機數序列都是相同的，從而使得程式的運行結果穩定不變。\n",
    "\n",
    "在一般學習、測試模型的時候，我們並不需要關心如何固定模型的參數，好讓模型可以重現 —— 但今天若是在科學實驗的背景下，如何讓一組模型的實驗可以重現，就是一件非常重要的事情了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BxrEMj-3XYzk"
   },
   "outputs": [],
   "source": [
    "# In order to reproduce the result of the model.\n",
    "def setup_seed(seed):\n",
    "   torch.manual_seed(seed)\n",
    "   torch.cuda.manual_seed(seed)\n",
    "   torch.cuda.manual_seed_all(seed)\n",
    "   np.random.seed(seed)\n",
    "   random.seed(seed)\n",
    "   torch.backends.cudnn.benchmark = False\n",
    "   torch.backends.cudnn.deterministic = True\n",
    "   torch.backends.cudnn.enabled = True\n",
    "\n",
    "setup_seed(8888)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XDRpO_kVZx1r"
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RYcELUOuaeDd"
   },
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3O0a95sIZAlR"
   },
   "outputs": [],
   "source": [
    "# use colab default dataset (parse into pandas dataframe)\n",
    "housing_train_df = pd.read_csv('sample_data/california_housing_train.csv')\n",
    "housing_test_df = pd.read_csv('sample_data/california_housing_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OwzpPQPRagXQ"
   },
   "source": [
    "### Normalize and Show Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SpJrqAguaGiE",
    "outputId": "d36c9eef-4594-4bde-ce46-63268f3e661b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-f1d4fec8-d57a-4e87-96c7-7410d6c656ee\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.623352</td>\n",
       "      <td>-0.672591</td>\n",
       "      <td>-1.083095</td>\n",
       "      <td>1.366966</td>\n",
       "      <td>1.771168</td>\n",
       "      <td>-0.362989</td>\n",
       "      <td>-0.072107</td>\n",
       "      <td>-1.251624</td>\n",
       "      <td>-1.213104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.543496</td>\n",
       "      <td>-0.574283</td>\n",
       "      <td>-0.765186</td>\n",
       "      <td>2.303412</td>\n",
       "      <td>3.240388</td>\n",
       "      <td>-0.262197</td>\n",
       "      <td>-0.095684</td>\n",
       "      <td>-1.079867</td>\n",
       "      <td>-1.098875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.498578</td>\n",
       "      <td>-0.906658</td>\n",
       "      <td>-0.924141</td>\n",
       "      <td>-0.880871</td>\n",
       "      <td>-0.865347</td>\n",
       "      <td>-0.965969</td>\n",
       "      <td>-1.002085</td>\n",
       "      <td>-1.168851</td>\n",
       "      <td>-1.050414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.493587</td>\n",
       "      <td>-0.930065</td>\n",
       "      <td>-1.162572</td>\n",
       "      <td>-0.522007</td>\n",
       "      <td>-0.477834</td>\n",
       "      <td>-0.805056</td>\n",
       "      <td>-0.716543</td>\n",
       "      <td>-0.358055</td>\n",
       "      <td>-1.156855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.493587</td>\n",
       "      <td>-0.962834</td>\n",
       "      <td>-0.685709</td>\n",
       "      <td>-0.543603</td>\n",
       "      <td>-0.503985</td>\n",
       "      <td>-0.708685</td>\n",
       "      <td>-0.622235</td>\n",
       "      <td>-1.024614</td>\n",
       "      <td>-1.225219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>-0.146649</td>\n",
       "      <td>-0.564920</td>\n",
       "      <td>-0.447278</td>\n",
       "      <td>-0.545441</td>\n",
       "      <td>0.247267</td>\n",
       "      <td>-0.148144</td>\n",
       "      <td>0.281546</td>\n",
       "      <td>-1.417172</td>\n",
       "      <td>0.155051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>0.711802</td>\n",
       "      <td>-0.733449</td>\n",
       "      <td>-0.129369</td>\n",
       "      <td>1.203846</td>\n",
       "      <td>1.293314</td>\n",
       "      <td>1.830551</td>\n",
       "      <td>1.405379</td>\n",
       "      <td>-0.253390</td>\n",
       "      <td>0.260627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>-0.066793</td>\n",
       "      <td>0.315171</td>\n",
       "      <td>-1.480481</td>\n",
       "      <td>-0.772430</td>\n",
       "      <td>-0.801158</td>\n",
       "      <td>-0.647680</td>\n",
       "      <td>-0.732261</td>\n",
       "      <td>-0.832808</td>\n",
       "      <td>-1.255507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>1.220883</td>\n",
       "      <td>-0.714723</td>\n",
       "      <td>0.903834</td>\n",
       "      <td>-1.167594</td>\n",
       "      <td>-1.245728</td>\n",
       "      <td>-1.219716</td>\n",
       "      <td>-1.271910</td>\n",
       "      <td>-0.316431</td>\n",
       "      <td>-0.385807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>-0.031857</td>\n",
       "      <td>-0.564920</td>\n",
       "      <td>1.062789</td>\n",
       "      <td>-0.400701</td>\n",
       "      <td>-0.653760</td>\n",
       "      <td>-0.594632</td>\n",
       "      <td>-0.627474</td>\n",
       "      <td>2.467258</td>\n",
       "      <td>2.534837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 9 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f1d4fec8-d57a-4e87-96c7-7410d6c656ee')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-f1d4fec8-d57a-4e87-96c7-7410d6c656ee button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-f1d4fec8-d57a-4e87-96c7-7410d6c656ee');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0       2.623352 -0.672591           -1.083095     1.366966        1.771168   \n",
       "1       2.543496 -0.574283           -0.765186     2.303412        3.240388   \n",
       "2       2.498578 -0.906658           -0.924141    -0.880871       -0.865347   \n",
       "3       2.493587 -0.930065           -1.162572    -0.522007       -0.477834   \n",
       "4       2.493587 -0.962834           -0.685709    -0.543603       -0.503985   \n",
       "...          ...       ...                 ...          ...             ...   \n",
       "19995  -0.146649 -0.564920           -0.447278    -0.545441        0.247267   \n",
       "19996   0.711802 -0.733449           -0.129369     1.203846        1.293314   \n",
       "19997  -0.066793  0.315171           -1.480481    -0.772430       -0.801158   \n",
       "19998   1.220883 -0.714723            0.903834    -1.167594       -1.245728   \n",
       "19999  -0.031857 -0.564920            1.062789    -0.400701       -0.653760   \n",
       "\n",
       "       population  households  median_income  median_house_value  \n",
       "0       -0.362989   -0.072107      -1.251624           -1.213104  \n",
       "1       -0.262197   -0.095684      -1.079867           -1.098875  \n",
       "2       -0.965969   -1.002085      -1.168851           -1.050414  \n",
       "3       -0.805056   -0.716543      -0.358055           -1.156855  \n",
       "4       -0.708685   -0.622235      -1.024614           -1.225219  \n",
       "...           ...         ...            ...                 ...  \n",
       "19995   -0.148144    0.281546      -1.417172            0.155051  \n",
       "19996    1.830551    1.405379      -0.253390            0.260627  \n",
       "19997   -0.647680   -0.732261      -0.832808           -1.255507  \n",
       "19998   -1.219716   -1.271910      -0.316431           -0.385807  \n",
       "19999   -0.594632   -0.627474       2.467258            2.534837  \n",
       "\n",
       "[20000 rows x 9 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df = pd.concat([housing_train_df, housing_test_df], ignore_index = True)\n",
    "\n",
    "# Normalizing. In order to get prettier result\n",
    "housing_df = (housing_df - housing_df.mean()) / housing_df.std() \n",
    "\n",
    "housing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FWeiWUCLASd1",
    "outputId": "e6dcb93d-9661-4592-cdf1-323bb7c08895"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.53483684816792\n",
      "-1.6622413519178973\n"
     ]
    }
   ],
   "source": [
    "print(housing_df.loc[housing_df[\"median_house_value\"].idxmax(), \"median_house_value\"]) # max median_house_value\n",
    "print(housing_df.loc[housing_df[\"median_house_value\"].idxmin(), \"median_house_value\"]) # min median_house_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RKfz-lhDcS4j"
   },
   "source": [
    "### Split Training(80%) and Testing(20%) Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1mZv0Andaj2X",
    "outputId": "b93301e2-939b-4d9f-e9bc-667818405561"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 20000, Training: 16000, Testing: 4000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "# random sample\n",
    "# to reproduce result, give random_state\n",
    "# housing_train_df, housing_test_df = train_test_split(housing_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# order sample\n",
    "housing_train_df = housing_df.loc[:15999]\n",
    "housing_test_df = housing_df.loc[16000:]\n",
    "\n",
    "print(f\"Total {len(housing_df)}, Training: {len(housing_train_df)}, Testing: {len(housing_test_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IaVvg8a4gvNb"
   },
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "inWBLD-Fg_YD"
   },
   "outputs": [],
   "source": [
    "class HousingDataset(Dataset): # inherit Dataset\n",
    "\n",
    "  def __init__(self, dataframe):\n",
    "    self.dataframe = dataframe\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    row = self.dataframe.iloc[index].to_numpy().astype('float32') # using index to locate a data row\n",
    "    features = row[0:-1] # get all columns except last one\n",
    "    label = row[-1] # last column => we want to predict\n",
    "    return features, label\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qPfRq1EjlTvL"
   },
   "outputs": [],
   "source": [
    "setup_seed(8888)\n",
    "\n",
    "train_dataset = HousingDataset(housing_train_df.astype('float32'))\n",
    "test_dataset = HousingDataset(housing_test_df.astype('float32'))\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = len(housing_train_df), shuffle = True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size = len(housing_test_df), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jHKo4Kwmlj-k",
    "outputId": "264b9ff8-e6e1-478e-8665-58fcbe5df940"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "OHOh9llagxYK"
   },
   "source": [
    "## Two Layers NN model\n",
    "<img\n",
    "width=\"400px\"\n",
    "src=\"https://lh3.googleusercontent.com/fife/APg5EOY5Wy3AN6M4KDimIyEQnTJnhEJ1JwouragqyVUtZPzD2pnEhxvpIHnOgjSGUwEycILoFhG3VfnIPpzYdBow6n-T3mSKvkYZhwJo_ht7pRCU7Yk6M-sMQJxolW8rrxS_m35ud2VB_QmgKPpP7C5d9R9SGlyyj5xTmD1HOkORhgb9cLnXQ1zYkjxHXVkrR9KPPo3kgezTXjkt0JBfP-LQ5_H7l3laZTiXkL4j5YEyWjNEBVGR8M4yoLaOBkYi6kbMFbylXzpifCtl-Beh0pUOOxzTKe0SJ5iTX9KTB28ZIw_Zi2IKBEC_5xm5-e9_v_noG7DmZ60FSnLDTRHR3uqJ399En7IaqTGxNKuJfaJuFGn0RufAzXsYdVfq7MVASpW2tJNdrIamJARUmeaxjKjCtmHyvuIQ0OMk4MsDGPP5AQSxkk6JXTfa4H6YDwKTDPo3YD6EYdDCZKd6YIg9KiOpr5zW1ECa0DO3OPkRTtbl1VaFzvfgRIdn170jOn_VcgpVJxeJMMjs5RdvqtVFZdT_mAx7kw7kS6vrE4Rr87bfu6e2obaLNvKgTymnDRdQ8j9s9OGHPnppLrMnTi8XuqN_jhk4k9nqlZKgjeyXVbd1PZTPA8tCDUYQIeSNjDY0HNS--mklImJqsEwArCTCkNp99Xy4CfSY7jSeJgvc4IWRM6POKPbPoXypf_L5S3FEXaPD3mX5Ce-dX7kCcRGH2Jt2e3LtV536QgmIDWi9rZ6VKIPevAjXyV15pYDlwIX2T6FIDCmj1mZawbbEYMYlSxsCRPYQRYWDq6I0wsOwgoF_nN5vFN2aUV4NllMjEO-F4XeAyfNEpxue4JBDOOJklvTnzWQtAM0459EX1ZLQEB9MOLk2J9vFs1qBrLDKTibLIz_pAgyVgJElm8_fHPXKgF9682o2S-Is24Q-uom_gZkUQi_rld4-fJH9wdkw3Ep0z6JvQgPfVbls7rkuqyLW0vJiQ-Eh3FsZobiC4hcIENM55LX87Wd9gfVlo9R1DvsAG6Dzq7-o2XxNC_KZv1DuZcI-iXBI78IskScLKbs8yzFQt2X0C4IRcS61WTkz0rNsa73PJSCyuFYmESYqbQy69oNvtLq-N5HMuij6NZRkJ46PwmphBlsCZQMAXOTQtoVaUf2VcH9bode538ADY6GCHCfmTaCCsaWqvIuV242UesYUcaEtNbO9-taiC5M7mSHj5fb0ZJhtkqA8HTCVk-fzo2wLG5qt06Ph3rvZCcuCM_M3yjUTyNOW-V2cKiNh5D0-3fnhkps49PL4smC_IcbuMYFgc6z2ZD-Gp2mO2Rg9O3rEetJctylCkXV1n_XG7gyb-YiSrtSXPwRnE1yAgzAlWhFexD-W_5Dyba0GmS48YTo6XG9bhwDOGo9KzrXEigSPvjal1-AKJz_HWI6-8R_JGhiWGHrNCZUg_wSqCPsGZZci7a5kE5arVFUZ1Z2qmtMG0--IG3c_xuU7at6PyCE_EjsXtUafAQrZsNZ93c4sffdmo-bUZUZFgLA5jIsGIVIzJrA4HYgpA1U6PnwxM29B0VQdn09wSpgLaeDSnzFHnmiw7uuNus9m4J0ApxRjgHkwx-q2MqY=w1252-h1622\"></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vHDzj_pRcx6k"
   },
   "outputs": [],
   "source": [
    "class TwoLayerNNModel(torch.nn.Module):\n",
    "\n",
    "  def __init__(self, D_in, H, D_out, activation_func, initial_weights = None):\n",
    "    super(TwoLayerNNModel, self).__init__()\n",
    "    self.linear1 = torch.nn.Linear(D_in, H) # FC1 (fully connected)\n",
    "    self.BatchNorm1 = torch.nn.BatchNorm1d(H) # BN1 (batch normalization)\n",
    "    self.linear2 = torch.nn.Linear(H, D_out)\n",
    "    \n",
    "    self.activation_func = activation_func\n",
    "    if activation_func == 'ReLU':\n",
    "      self.relu = torch.nn.ReLU()\n",
    "    if activation_func == 'Tanh':\n",
    "      self.tanh = torch.nn.Tanh()\n",
    "\n",
    "    self.initial_weights = initial_weights\n",
    "    if self.initial_weights == 'small random number':\n",
    "      # H = W * X + B ; X = D_in\n",
    "      # numpy mutiplication is not the same as the linear algebra\n",
    "      self.linear1.weight = torch.nn.Parameter(0.01 * torch.FloatTensor(np.random.randn(H, D_in))) # transpose\n",
    "      self.linear2.weight = torch.nn.Parameter(0.01 * torch.FloatTensor(np.random.randn(D_out, H)))\n",
    "    \n",
    "    #the other two ways to initialize weight\n",
    "    if self.initial_weights == 'Xavier':\n",
    "      torch.nn.init.xavier_uniform_(self.linear1.weight)\n",
    "      torch.nn.init.xavier_uniform_(self.linear2.weight)\n",
    "    if self.initial_weights == 'Kaiming':\n",
    "      torch.nn.init.kaiming_uniform_(self.linear1.weight)\n",
    "      torch.nn.init.kaiming_uniform_(self.linear2.weight)\n",
    "  \n",
    "  # input -> FC1 -> BN1 -> ReLU -> FC2 -> output\n",
    "  def forward(self, x): # input\n",
    "    layer1 = self.linear1(x) # FC1\n",
    "    \n",
    "    batchnorm1 = self.BatchNorm1(layer1) # BN1\n",
    "\n",
    "    # activation\n",
    "    activation = None\n",
    "    if self.activation_func == 'ReLU':\n",
    "      activation = self.relu(batchnorm1)\n",
    "    if self.activation_func == 'Tanh':\n",
    "      activation = self.tanh(batchnorm1)\n",
    "    \n",
    "    pred = self.linear2(activation) # FC2\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sDibE3mYDRqg"
   },
   "source": [
    "## Initial Model Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EIx1OvbN9nl6"
   },
   "outputs": [],
   "source": [
    "D_in = len(housing_train_df.columns) - 1 # all features except the last one(label)\n",
    "D_out = 1 # predict the label(median_house_value)\n",
    "hidden_nodes = [5, 8, 11] # different numbers of hidden nodes. can choose what you want\n",
    "learning_rate = 1e-3 # init learning rate\n",
    "loss_fn = torch.nn.MSELoss().to(device) # loss function using Mean Square Error(MSE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "pa0oBfCY-jHu"
   },
   "source": [
    "## Weight_Tuning_LG_UA\n",
    "Learning Goal and Undesired Atractor\n",
    "\n",
    "<img\n",
    "width=\"800px\"\n",
    "src=\"https://lh3.googleusercontent.com/fife/APg5EOayfdh75y3GoQFbkRCItgxGSZ-1eof4NsPzJQEqpT4w8fhhDrHVjJlNQmZ-OUoQgb-bFut3iP6Iuu39GHkcoe6H4ehAzoxRmHrlsvw8mJWI0xd63coNptj0djVX2EFSVE_MM4MZDvbsQBjMToUOvi1oynYXtJ_LhuFJTzS4VYr-8J4AVjTGGiptn4G-wR5OJSr92qO06VHVRIj0UPEHIu0VAvjYTat615nmAsVfD0N3TqKpHITgd_ylAiJJGas6WlH_O21hEBn95sRjVShQMW1pN6zFWre-HEgemhO9mJkr6dBQ-xaTpqDhM6MjhjICasoX9ZJlc1cKl8hoGWnJieUpCMBUnHJEZpXhtks0rCOs3GqjjEaW035n9ODHY4iUBuqjO6OqgwjceMkbRhdYEKQZok6TBY6iRthc8ECXJWAMzycJIB9Y7DH9tYL9xWS1Rrd09rduPb0JVu588UhQfDs8VBFXeBu4v4Cf8P3UaMp-6zwGXxo6OcygKZWa-f9xYHDEjzvpLR8rRhfGX9AgIbTzbOkm1aURiuHqpNOqiNiSNDw_cWTLVYHlEBZA6JXklYdWi8Za08pE7nNzepenBNL50fa5bfBhjqMaj5WBfEQW3dlVLbUEim3FZY6hwGqbmyAfhGaMOR-otLyA63PXqNOKvCGXCTqFCnDDLKET7QY5044io4BCkmpJXf92V_G97Gv9WFGyIIHO1SZb6sBEAzHtT59OOaQTvApZ6LxeZi3v6-yKn5tHrmzL9UPEwt_9StSShFvO3D-LG2tAJHcGBNHHOqbQkJpBKTzmgKXq4SjwNk0MxXZmAJu_2CrOw1N0IZI1O3VnpJnLhYsmmQnNEeDs3KskYmRD4QMURNnXLTphr9fV0iXzmtyVCV9864Q_9Mwgtj3-TTdgpNicY9mVVIUqjcIPACfsu7Vfm_DaHcJgIbpfNH4rR-q2Zyk08DKE2feJbiYoPobLqGg96c-El06XsQ-Ymsrp7ubozZnjs6IZVJnzVfviIhfGJGboG2ckKtrUjwW0buFV8JmgotJuDFpWELQUlbPTRDdI0Ab9a3urdRYDlJJdkCiQZgz2xF4pVMFpAbSaTC2nEUrxg8K7-pDhJTrMe-1FPjwtEUXmu45r_qBX4WWgnUPPht2H2PXbF7DjLsz8ddqxqG6HG5cRY4gOvOSYxsazimlo66lico2HQIj-qcrq-Xi5hLiSQcWOoShtfpPsIPye9k6MnTJn0Fps0SvbJiC2xE3stx10OSgREvhBrFmMUZj_tXJ8RT39IdRWackBUICXvOsf0ykJi9bNMfdOZ5bv2A2rEFy30nfoLL7zw1buP_PN-KpTCcZ5wTe9znvyHXxvETag9scWEZY6vXLwyqJp64BFhbvb92WZkkio8JuEmTxj3T52sxnb9fPXj01ncjkHiLBBLkvTnqwn043vCvvQ86PNWX7Zhncegj9pgPjhO5OpCyGT3yXnHh-bbAFY76NtwOD4trcFO9BdajLhHEsRB7L54Qois8VBtS8iAA0GCDh8YVe1dVzgt39LXziqZWeIRpYDV_6pL3SJCfpo7K7KdjAcc_jf4-FEj_U2-Ru7Js3VwGwHnKebyDU=w1968-h1622\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5zKMX2KX_ugC"
   },
   "source": [
    "1. c is for c_th input data\n",
    "2. epsilon is 0.9905 (tolerant loss) => LG\n",
    "3. initial learning rate is 0.001\n",
    "4. epsilon1 is 0.00001 (tolerant min of learning rate) => UA\n",
    "  * may be caused by local min, saddle point, etc.\n",
    "\n",
    "Note: As soon as you meet the loop(at first entery point), build and loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8NYreTxv-yKj"
   },
   "outputs": [],
   "source": [
    "setup_seed(8888)\n",
    "\n",
    "model_LG_UA = TwoLayerNNModel(D_in, hidden_nodes[1], D_out, 'Tanh', 'small random number').to(device)\n",
    "optimizer_LG_UA = torch.optim.Adam(model_LG_UA.parameters(), lr = learning_rate) # Use Adam optimizer\n",
    "\n",
    "# Adam => Adaptive Moment Estimation => optimized gradient based optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jAGDo9WTjKjd"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QYQsuoC1jNsY",
    "outputId": "ac4d9e33-5df5-4915-f832-511e3424a6fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th round: \n",
      "initial forward operation: \n",
      "* total loss:  0.9949537515640259\n",
      "-------------------------------------\n",
      "1th round (now at LG): \n",
      "check stopping criteria(LG): \n",
      "LG not OK!\n",
      "Backward: calculate direction\n",
      "weight adjustment\n",
      "Forward Operation\n",
      "check if loss is less than the original one\n",
      "\n",
      "loss becomes smaller!\n",
      "lr = lr * 1.2\n",
      "update loss: 0.9947198629379272\n",
      "-------------------------------------\n",
      "2th round (now at LG): \n",
      "check stopping criteria(LG): \n",
      "LG not OK!\n",
      "Backward: calculate direction\n",
      "weight adjustment\n",
      "Forward Operation\n",
      "check if loss is less than the original one\n",
      "\n",
      "loss becomes smaller!\n",
      "lr = lr * 1.2\n",
      "update loss: 0.9944754838943481\n",
      "-------------------------------------\n",
      "3th round (now at LG): \n",
      "check stopping criteria(LG): \n",
      "LG not OK!\n",
      "Backward: calculate direction\n",
      "weight adjustment\n",
      "Forward Operation\n",
      "check if loss is less than the original one\n",
      "\n",
      "loss becomes smaller!\n",
      "lr = lr * 1.2\n",
      "update loss: 0.994215190410614\n",
      "-------------------------------------\n",
      "4th round (now at LG): \n",
      "check stopping criteria(LG): \n",
      "LG not OK!\n",
      "Backward: calculate direction\n",
      "weight adjustment\n",
      "Forward Operation\n",
      "check if loss is less than the original one\n",
      "\n",
      "loss becomes smaller!\n",
      "lr = lr * 1.2\n",
      "update loss: 0.993943989276886\n",
      "-------------------------------------\n",
      "5th round (now at LG): \n",
      "check stopping criteria(LG): \n",
      "LG not OK!\n",
      "Backward: calculate direction\n",
      "weight adjustment\n",
      "Forward Operation\n",
      "check if loss is less than the original one\n",
      "\n",
      "loss becomes smaller!\n",
      "lr = lr * 1.2\n",
      "update loss: 0.9936684370040894\n",
      "-------------------------------------\n",
      "6th round (now at LG): \n",
      "check stopping criteria(LG): \n",
      "LG not OK!\n",
      "Backward: calculate direction\n",
      "weight adjustment\n",
      "Forward Operation\n",
      "check if loss is less than the original one\n",
      "\n",
      "loss becomes smaller!\n",
      "lr = lr * 1.2\n",
      "update loss: 0.9933728575706482\n",
      "-------------------------------------\n",
      "7th round (now at LG): \n",
      "check stopping criteria(LG): \n",
      "LG not OK!\n",
      "Backward: calculate direction\n",
      "weight adjustment\n",
      "Forward Operation\n",
      "check if loss is less than the original one\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([16000])) that is different to the input size (torch.Size([16000, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "loss becomes smaller!\n",
      "lr = lr * 1.2\n",
      "update loss: 0.9930391311645508\n",
      "-------------------------------------\n",
      "8th round (now at LG): \n",
      "check stopping criteria(LG): \n",
      "LG not OK!\n",
      "Backward: calculate direction\n",
      "weight adjustment\n",
      "Forward Operation\n",
      "check if loss is less than the original one\n",
      "\n",
      "loss becomes smaller!\n",
      "lr = lr * 1.2\n",
      "update loss: 0.9926501512527466\n",
      "-------------------------------------\n",
      "9th round (now at LG): \n",
      "check stopping criteria(LG): \n",
      "LG not OK!\n",
      "Backward: calculate direction\n",
      "weight adjustment\n",
      "Forward Operation\n",
      "check if loss is less than the original one\n",
      "\n",
      "loss becomes smaller!\n",
      "lr = lr * 1.2\n",
      "update loss: 0.9922142624855042\n",
      "-------------------------------------\n",
      "10th round (now at LG): \n",
      "check stopping criteria(LG): \n",
      "LG not OK!\n",
      "Backward: calculate direction\n",
      "weight adjustment\n",
      "Forward Operation\n",
      "check if loss is less than the original one\n",
      "\n",
      "loss becomes smaller!\n",
      "lr = lr * 1.2\n",
      "update loss: 0.9917640089988708\n",
      "-------------------------------------\n",
      "11th round (now at LG): \n",
      "check stopping criteria(LG): \n",
      "LG not OK!\n",
      "Backward: calculate direction\n",
      "weight adjustment\n",
      "Forward Operation\n",
      "check if loss is less than the original one\n",
      "\n",
      "loss becomes smaller!\n",
      "lr = lr * 1.2\n",
      "update loss: 0.9913185238838196\n",
      "-------------------------------------\n",
      "12th round (now at LG): \n",
      "check stopping criteria(LG): \n",
      "LG not OK!\n",
      "Backward: calculate direction\n",
      "weight adjustment\n",
      "Forward Operation\n",
      "check if loss is less than the original one\n",
      "\n",
      "loss becomes smaller!\n",
      "lr = lr * 1.2\n",
      "update loss: 0.9908888936042786\n",
      "-------------------------------------\n",
      "13th round (now at LG): \n",
      "check stopping criteria(LG): \n",
      "LG not OK!\n",
      "Backward: calculate direction\n",
      "weight adjustment\n",
      "Forward Operation\n",
      "check if loss is less than the original one\n",
      "\n",
      "loss becomes smaller!\n",
      "lr = lr * 1.2\n",
      "update loss: 0.990588366985321\n",
      "-------------------------------------\n",
      "14th round (now at LG): \n",
      "check stopping criteria(LG): \n",
      "LG not OK!\n",
      "Backward: calculate direction\n",
      "weight adjustment\n",
      "Forward Operation\n",
      "check if loss is less than the original one\n",
      "\n",
      "loss becomes smaller!\n",
      "lr = lr * 1.2\n",
      "update loss: 0.9904861450195312\n",
      "-------------------------------------\n",
      "15th round (now at LG): \n",
      "check stopping criteria(LG): \n",
      "LG OK!\n",
      "\n",
      "-------------------------------------\n",
      "Acceptable SLFN\n",
      "loss: 0.9904861450195312\n"
     ]
    }
   ],
   "source": [
    "# we set one batch = dataset size, so it gonna loop onece\n",
    "for batch, (X, y) in enumerate(train_dataloader):\n",
    "\n",
    "  t = 0\n",
    "  isLGSatisfied = False\n",
    "  isMeetUA = False\n",
    "  \n",
    "  epsilon = 0.9905\n",
    "  epsilon1 = 1e-5\n",
    "\n",
    "  # forward\n",
    "  print(f\"{t}th round: \")\n",
    "\n",
    "  print('initial forward operation: ')\n",
    "  pred = model_LG_UA(X.to(device))\n",
    "  loss = loss_fn(pred, y.to(device))\n",
    "  print('* total loss: ', loss.item())\n",
    "  print('-------------------------------------')\n",
    "  \n",
    "  # Store w first\n",
    "  original_param = {}\n",
    "  for param in model_LG_UA.parameters():\n",
    "    original_param[param] = param\n",
    "\n",
    "  # weight tuning\n",
    "  # loop1\n",
    "  while not isLGSatisfied:\n",
    "    t+=1\n",
    "    print(f\"{t}th round (now at LG): \")\n",
    "    print('check stopping criteria(LG): ')\n",
    "    \n",
    "    if loss.item() < epsilon:\n",
    "      print(\"LG OK!\")\n",
    "      isLGSatisfied = True\n",
    "      break\n",
    "\n",
    "    else:\n",
    "      print(\"LG not OK!\")\n",
    "     \n",
    "      # if put ouside the loop, need to retain graph\n",
    "      print('Backward: calculate direction')\n",
    "      loss.backward() # calculate direction\n",
    "\n",
    "      # loop2\n",
    "      while not isMeetUA:\n",
    "        print('weight adjustment')\n",
    "        optimizer_LG_UA.step()\n",
    "\n",
    "        print(\"Forward Operation\")\n",
    "        pred2 = model_LG_UA(X.to(device))\n",
    "        loss2 = loss_fn(pred2, y.to(device))\n",
    "\n",
    "        print(\"check if loss is less than the original one\")\n",
    "        \n",
    "        if loss2.item() < loss.item():\n",
    "          print(\"\\nloss becomes smaller!\")\n",
    "\n",
    "          print('lr = lr * 1.2')\n",
    "          optimizer_LG_UA.param_groups[0]['lr'] *= 1.2\n",
    "\n",
    "          print(f\"update loss: {loss2}\")\n",
    "          loss = loss2\n",
    "\n",
    "          print('-------------------------------------')\n",
    "\n",
    "          # clean gradient\n",
    "          optimizer_LG_UA.zero_grad()\n",
    "\n",
    "          break\n",
    "\n",
    "        else:\n",
    "          print(\"\\nloss becomes bigger!\")\n",
    "\n",
    "          t+=1\n",
    "          print(f\"\\n{t}th round (now at UA)\")\n",
    "          print(\"check stopping criteria(UA): \")\n",
    "          if optimizer_LG_UA.param_groups[0]['lr'] > epsilon1:\n",
    "            print(\"haven't met UA!\")\n",
    "\n",
    "            # restore w\n",
    "            print(\"restore w\")\n",
    "            for param in model_LG_UA.parameters():\n",
    "              param = original_param[param]\n",
    "\n",
    "            # step smaller\n",
    "            print('lr = lr * 0.7')\n",
    "            optimizer_LG_UA.param_groups[0]['lr'] *= 0.7 \n",
    "\n",
    "            print('-------------------------------------')\n",
    "\n",
    "            # clean gradient\n",
    "            optimizer_LG_UA.zero_grad()\n",
    "\n",
    "            continue\n",
    "            \n",
    "          else:\n",
    "            print(\"have met UA!\")\n",
    "            print('-------------------------------------')\n",
    "            isMeetUA = True\n",
    "          \n",
    "    if isMeetUA:\n",
    "      break\n",
    "\n",
    "  if isLGSatisfied == True:\n",
    "    print('\\n-------------------------------------')\n",
    "    print(\"Acceptable SLFN\")\n",
    "  else:\n",
    "    print('\\n-------------------------------------')\n",
    "    print(\"Unacceptable SLFN\")\n",
    "\n",
    "  print(f\"loss: {loss}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "LT3jDthd16bv"
   },
   "source": [
    "## Weight_Tuning_EB_LG_UA\n",
    "Epoch Bound, Learning Goal and Undesired Atractor\n",
    "\n",
    "<img\n",
    "width=\"800px\"\n",
    "src=\"https://lh3.googleusercontent.com/fife/APg5EObrIm-J8ma5lVE5NYf99Negf9-lzdMcOx5cYtHbhsJlv1xKE86lG8ZQuDI7VUIQvwanx6dvbrZEE43YvxmlDddX2wj973UqOFhoRKreWyiYQisdz-RDuW11U7u4z0fSfHw7LHi2LRxuLJjQKUjkSZ5CQ74n8L8Av-SPsoxEeyWtGopJ8g1DeLefCM3m-Y2gKy1FxuON3yNB4QFM1E2LASm8KX43arpzr-ndD29oC67qKGyra_nH4pGrpF0JRsMLB36aKYGMGodIQjV2smDPOBvFxaa5viWgQdKGBqXLFi8HR74iKSNCPk--B_eIGw2aNCtJjyZViBtn-iylCcsjSUZn4I9fjUQ23E0qxoEZwRBHrXavM9_WCHrdD2qRm4JG28XnGW0VuPu_iHF4K11n7EFx5rdHOl7_cFRWZdv9RD-tF0jwSfntl7BP8mfzTrNpPVE8njggSYFqP8H6gDp57Mlq_gQKdNp8SKmOeyaQd9QSab0tujCi4q7_fdBqBKGZPBQusxG-iZO-da-_LGVD7VOcWFCY99WET1BmaOs_ZgAl0lQvjCI89jVhIfgozzBongWwsRQtHGSIheL3ptKd12aBLxMv-tGKd8ZkxfSAT7imK3PaRey791EnADXLQ_WhcfQGkugSQz-e_PtlWUrcVzA0-cHaWM7u-f7BFLm4fJVKLLkE9MIpNpDX6YZP5pG_KCUVzB0q2zOX-pH9n8ZmSMUD-qlUu-E11RQR6qecBAnlWBcTM-rT68CnBm6_BUJ-zHCKLFJ9IEBPISIQVcBLs7OMqvsam0fEGhKNwN_2l_-7VmB_CwGvICokesVoynW5ssa7inAcYmpO4Lg-iUfTX6humQQD8IQC5OBddjQAiqeBbqVtt8qE6Irv8sVCz_Xh7uneezK1ci-4yetXJALzqK4wh6lZGTYzaEj3RCGFFRW9VKdhNuGRH936Dzu8_gmMk8RAvsr4otXMHTGRg1A7DNE74eO6ArT0bv3qOnJQSn9UiEDx6bag7txHY5l2H9rsXfqYfo-RngErNAbr-fn0IhC0pgIhfVEuMVNTOFBOEA9mV-mA2ijkwxA4DxyuPTIarkMpxfhMD6vtqC-HQF2nosYQG0fODrRQn4tC2PG4ey6yg1bhqaWsWc32AbzUnSrk1I88kVRM1sIosFvV1UFmYRp_0MIyesmg4_1uHjpjbI-FXj3sNj3l4eA2nX6mgopYXOLCrvVtXIZMYHh_s1rJVPOvRH48Q5vHfV8it2Tq1wvI4oqWgX8oJ8XjuBQpY4Z-LsFpQ-G0fRlP9fgzyK6NIEM_p4VPlVU4I-Zt97Gmaw1NyDGWNdLkP-nRl4G0fFlALh1RojYAcnTVFydAINTG0kp5KJZ24XC-dWZ9VxTQoySxGrzxW3Wf5bcE23VEqNkF0Uz8a31_o5zofFDEgkue4V7w4xaVsDTJy0Cop-kkV2b2R6b2G6x8t20VCxSRw43WMTdgkD55MJoTel6L7LyAsYXacdF3RjPYRclh-HIFvBM0KUPplEBoYbTjX2kD7OFTY70eAvWnnd_C1-Lfj-hhHmE72EBSxEagRfc5udTYPnI2nV0zBb1PZ-GarmuxHGiSF_s=w2000-h4328\"></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JXm8XlFx2Dwu"
   },
   "outputs": [],
   "source": [
    "setup_seed(8888)\n",
    "epoch_bound = 50\n",
    "\n",
    "model_EB_LG_UA = TwoLayerNNModel(D_in, hidden_nodes[1], D_out, 'Tanh', 'small random number').to(device)\n",
    "optimizer_EB_LG_UA = torch.optim.Adam(model_LG_UA.parameters(), lr = learning_rate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xl-SR57OicmL",
    "outputId": "45fd453d-e841-4862-ead4-277c0d5ff789"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th round: \n",
      "initial forward operation: \n",
      "* total loss:  0.9904861450195312\n",
      "-------------------------------------\n",
      "1th round (now at LG)\n",
      "check stopping criteria(LG): \n",
      "LG OK!\n",
      "\n",
      "-------------------------------------\n",
      "Acceptable SLFN\n",
      "loss: 0.9904861450195312\n"
     ]
    }
   ],
   "source": [
    "# we set one batch = dataset size\n",
    "# so it gonna loop onece (every data => one epoch)\n",
    "for batch, (X, y) in enumerate(train_dataloader):\n",
    "\n",
    "  t = 0 \n",
    "  isLGSatisfied = False\n",
    "  isMeetUA = False\n",
    "  isMeetEpochBound = False\n",
    "  \n",
    "  epsilon = 0.9905\n",
    "  epsilon1 = 1e-5\n",
    "\n",
    "  # forward\n",
    "  print(f\"{t}th round: \")\n",
    "\n",
    "  print('initial forward operation: ')\n",
    "  pred = model_LG_UA(X.to(device))\n",
    "  loss = loss_fn(pred, y.to(device))\n",
    "  print('* total loss: ', loss.item())\n",
    "  print('-------------------------------------')\n",
    "  \n",
    "  # Store w first\n",
    "  original_param = {}\n",
    "  for param in model_LG_UA.parameters():\n",
    "    original_param[param] = param\n",
    "\n",
    "  # weight tuning\n",
    "  # loop1\n",
    "  while not isLGSatisfied:\n",
    "    print(f\"{t+1}th round (now at LG)\") # Cuz begining t = 0\n",
    "    print('check stopping criteria(LG): ')\n",
    "    \n",
    "    if loss.item() < epsilon:\n",
    "      print(\"LG OK!\")\n",
    "      isLGSatisfied = True\n",
    "      break\n",
    "\n",
    "    else:\n",
    "      print(\"LG not OK!\")\n",
    "     \n",
    "      # if put ouside the loop, need to retain graph\n",
    "      print('Backward: calculate direction')\n",
    "      loss.backward() # calculate direction\n",
    "\n",
    "      # loop2\n",
    "      while not isMeetUA:\n",
    "        print('weight adjustment')\n",
    "        optimizer_LG_UA.step()\n",
    "\n",
    "        print(\"Forward Operation\")\n",
    "        pred2 = model_LG_UA(X.to(device))\n",
    "        loss2 = loss_fn(pred2, y.to(device))\n",
    "\n",
    "        print(\"check if loss is less than the original one\")\n",
    "        \n",
    "        if loss2.item() < loss.item():\n",
    "          print(\"\\nloss becomes smaller!\")\n",
    "\n",
    "          print('lr = lr * 1.2')\n",
    "          optimizer_LG_UA.param_groups[0]['lr'] *= 1.2\n",
    "\n",
    "          print(f\"update loss: {loss2}\")\n",
    "          loss = loss2\n",
    "\n",
    "          # successfully weight tune once\n",
    "          t+=1\n",
    "          isMeetEpochBound = t == epoch_bound\n",
    "\n",
    "          if isMeetEpochBound:\n",
    "            print(\"Meet Epoch Bound!\")\n",
    "            break\n",
    "\n",
    "          print('-------------------------------------')\n",
    "\n",
    "          # clean gradient\n",
    "          optimizer_LG_UA.zero_grad()\n",
    "\n",
    "          break\n",
    "\n",
    "        else:\n",
    "          print(\"\\nloss becomes bigger!\")\n",
    "\n",
    "          print(f\"\\n{t}th round (now at UA)\")\n",
    "          print(\"check stopping criteria(UA): \")\n",
    "          if optimizer_LG_UA.param_groups[0]['lr'] > epsilon1:\n",
    "            print(\"haven't met UA!\")\n",
    "\n",
    "            # restore w\n",
    "            print(\"restore w\")\n",
    "            for param in model_LG_UA.parameters():\n",
    "              param = original_param[param]\n",
    "\n",
    "            # step smaller\n",
    "            print('lr = lr * 0.7')\n",
    "            optimizer_LG_UA.param_groups[0]['lr'] *= 0.7 \n",
    "\n",
    "            print('-------------------------------------')\n",
    "\n",
    "            # clean gradient\n",
    "            optimizer_LG_UA.zero_grad()\n",
    "\n",
    "            continue\n",
    "            \n",
    "          else:\n",
    "            print(\"have met UA!\")\n",
    "            print('-------------------------------------')\n",
    "            isMeetUA = True\n",
    "          \n",
    "    if isMeetUA:\n",
    "      break\n",
    "\n",
    "    if isMeetEpochBound:\n",
    "      break\n",
    "\n",
    "  if isLGSatisfied == True:\n",
    "    print('\\n-------------------------------------')\n",
    "    print(\"Acceptable SLFN\")\n",
    "  else:\n",
    "    print('\\n-------------------------------------')\n",
    "    print(\"Unacceptable SLFN\")\n",
    "\n",
    "  print(f\"loss: {loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z1m9OD4Piedl"
   },
   "source": [
    "## Export Model\n",
    "* .pt \n",
    "  * save the state of pytorch model (including parameters)\n",
    "  * can load later and train\n",
    "\n",
    "* .pth\n",
    "  * store pre-trained model weights that can be loaded into a PyTorch model\n",
    "  * fine-tune the model on your own dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "skPOgyStifwk"
   },
   "outputs": [],
   "source": [
    "torch.save(model_LG_UA, 'model_LG_UA.pt')\n",
    "torch.save(model_EB_LG_UA, 'model_EB_LG_UA.pt')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMjbFmB5dWPoTAn6ii/8Cr/",
   "collapsed_sections": [
    "4mooD8iHY0fn",
    "RYcELUOuaeDd",
    "OwzpPQPRagXQ",
    "IaVvg8a4gvNb",
    "OHOh9llagxYK",
    "sDibE3mYDRqg",
    "pa0oBfCY-jHu",
    "jAGDo9WTjKjd"
   ],
   "include_colab_link": true,
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
