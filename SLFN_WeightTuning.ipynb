{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "4mooD8iHY0fn",
        "RYcELUOuaeDd",
        "OwzpPQPRagXQ",
        "IaVvg8a4gvNb",
        "OHOh9llagxYK",
        "sDibE3mYDRqg",
        "pa0oBfCY-jHu",
        "jAGDo9WTjKjd"
      ],
      "authorship_tag": "ABX9TyMjbFmB5dWPoTAn6ii/8Cr/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mao-code/SLFN_WeightTuning/blob/main/SLFN_WeightTuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This is based on the HW3 of New Learning Algorithm class.\n",
        "<img \n",
        "width=\"500px\"\n",
        "src=\"https://lh3.googleusercontent.com/fife/APg5EOZwrOY0oLYi8YBH38hc_wuinI82mVPRcphGYdR72lxn9aZISGLKs1_OLCXGPF90SVd3hpzHRq9MCxgvCq6IGSyv2winW34Qj16nBvYEddYIvwzQ6hYaWH1kAgVXnfp8FE_e5beZTKDxXmK6dfLwrrYj-G1POJSfaU-Q7VCM1392hTfOqSsS8ZQQQhgV7cYh9mWDVwnhNcTE3qRoqjX_8FceEgiQYUurcNysmEsiGgnB7NkFzoyulDWTYXqBxjJU5T1lMvWCOIliO3lnfcUZIQ24dPj2RnLge95p4axVNBwTq7ZY8BsM0S0FrnBe_fzEY6Nm6Qbl24RXPQXUuP0S7SbIgz1BEkbvjzB5AY9r3o9GUS9Bk5idLqULNOZq9or9onL5Z8O2C_Tkwx1s660x3twZgeF4m3BUPBpjSjmckdCBZFCBeIM-OyG45FJJ7pcRz1V_OPUouQHLWbgi70vGY6BiOBpZcR39Agq_XRNAH5ZTHemKJN9Vz1lbd_FAAldOfdINCM0JJoh_RWvOYuJYO_XolnatONqvsQBxGRwLD-6J_fdLOCec5G8CA42xfs1ycM5mNcc24bVG8Q4dyuetbEF2jJ0qahu1LplQY4YM2rklkcWqAeXm0Qu119gd0lZBhucXDn5lamLXBA5h1xTeFXVsgKuW75hElDjIbBjGt2mL-qIMq1Kw2t0uilsVQhSLv6ILo8eYtOWpvXO2aqmfRPpGcVv1mr0mfILRTNr6VTuLMSVaLFGX0ptBGfLn96xo5KDZPQid29oWQZnWvW-cw4OMzH43i-kqcRQOxT0PlXKLbqcCDFj8Bxb2ccD4xpcQQFb6yb62bMHTDrYd5BcxT9HpHJ5ZtHDI8sEPIOFeP8RtvxURLLKWC2vLRk46U6EkgvMtGteTA_aK07mmY0i1JOLElewJF3lP-5E6r0crBaFXO8v8tTSI6Ps4GL3d3Dkil0Q9NMua0n3piM-J2vg1te6e3QBhD0EwAP_Gj7EQ8EgAARnjyLMOG9QoQJb06PYbex_nvvXye5kIvoG-B_538XUjIMVGiAiDyVDnydMDPtaB6ZD4f0EK3t5DZ81IMjpYvnuDycm9EQ0OsR6jlJe23eBAm63ECsDgJo5rUOYldTFOnE4vtaP4T30ELhGCz_ti8hXKAe7Bu1-zUFvc131lHC0SJUAitxLQLc0GjO1t2nRvNXV1Yk1qKzL68aHzGKGR8L6OpMX7qAQ2sp25POhw2l4s0MKG3nPn-e9FaLvg4TgOQj-sw-eqGCvTf834tzI0ldJzSIHWpmWKPAMDR5wKVVWDm2lMIgGbQE28-LajH1FR9-qKqsFqVSrmmtvUYBQVMhwLS2_yQwtjBQzv51Rxa0PCJViFER9ZCgNaBG5EUcMrepiANCuBAXy_Fc64pbHGOD4_7aaYSgT-n53ql_3mqo0FtTDzAyeIdAvP08ib_0pH9jraUiFTw8CzAk_yNRWbM4zwDLzpHASFpFZRT6mISWCUVPQcrqSSMGDirtoUXej0qtB0yZESGJbsXweATfx1GrECWLRH25aHLxasYmRK_-ShPfl6INC6yYqEr5dG5AvFY0MH2ihXmZNxFnZPdFuWoVA=w2992-h1654\" alt=\"HW3\"></img>"
      ],
      "metadata": {
        "id": "L22uCWtuTx9i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IiKWSK4pP5zb"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup Seed\n",
        "在深度學習中，許多操作都涉及到隨機性，例如權重初始化、dropout、數據增強等。這些操作在沒有指定隨機種子的情況下，每次運行時都會生成不同的隨機數序列，從而導致不同的結果。而通過設定隨機種子，可以使得每次生成的隨機數序列都是相同的，從而使得程式的運行結果穩定不變。\n",
        "\n",
        "在一般學習、測試模型的時候，我們並不需要關心如何固定模型的參數，好讓模型可以重現 —— 但今天若是在科學實驗的背景下，如何讓一組模型的實驗可以重現，就是一件非常重要的事情了。"
      ],
      "metadata": {
        "id": "4mooD8iHY0fn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# In order to reproduce the result of the model.\n",
        "def setup_seed(seed):\n",
        "   torch.manual_seed(seed)\n",
        "   torch.cuda.manual_seed(seed)\n",
        "   torch.cuda.manual_seed_all(seed)\n",
        "   np.random.seed(seed)\n",
        "   random.seed(seed)\n",
        "   torch.backends.cudnn.benchmark = False\n",
        "   torch.backends.cudnn.deterministic = True\n",
        "   torch.backends.cudnn.enabled = True\n",
        "\n",
        "setup_seed(8888)"
      ],
      "metadata": {
        "id": "BxrEMj-3XYzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "XDRpO_kVZx1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Data"
      ],
      "metadata": {
        "id": "RYcELUOuaeDd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# use colab default dataset (parse into pandas dataframe)\n",
        "housing_train_df = pd.read_csv('sample_data/california_housing_train.csv')\n",
        "housing_test_df = pd.read_csv('sample_data/california_housing_test.csv')"
      ],
      "metadata": {
        "id": "3O0a95sIZAlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Normalize and Show Data"
      ],
      "metadata": {
        "id": "OwzpPQPRagXQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "housing_df = pd.concat([housing_train_df, housing_test_df], ignore_index = True)\n",
        "\n",
        "# Normalizing. In order to get prettier result\n",
        "housing_df = (housing_df - housing_df.mean()) / housing_df.std() \n",
        "\n",
        "housing_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpJrqAguaGiE",
        "outputId": "d36c9eef-4594-4bde-ce46-63268f3e661b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "0       2.623352 -0.672591           -1.083095     1.366966        1.771168   \n",
              "1       2.543496 -0.574283           -0.765186     2.303412        3.240388   \n",
              "2       2.498578 -0.906658           -0.924141    -0.880871       -0.865347   \n",
              "3       2.493587 -0.930065           -1.162572    -0.522007       -0.477834   \n",
              "4       2.493587 -0.962834           -0.685709    -0.543603       -0.503985   \n",
              "...          ...       ...                 ...          ...             ...   \n",
              "19995  -0.146649 -0.564920           -0.447278    -0.545441        0.247267   \n",
              "19996   0.711802 -0.733449           -0.129369     1.203846        1.293314   \n",
              "19997  -0.066793  0.315171           -1.480481    -0.772430       -0.801158   \n",
              "19998   1.220883 -0.714723            0.903834    -1.167594       -1.245728   \n",
              "19999  -0.031857 -0.564920            1.062789    -0.400701       -0.653760   \n",
              "\n",
              "       population  households  median_income  median_house_value  \n",
              "0       -0.362989   -0.072107      -1.251624           -1.213104  \n",
              "1       -0.262197   -0.095684      -1.079867           -1.098875  \n",
              "2       -0.965969   -1.002085      -1.168851           -1.050414  \n",
              "3       -0.805056   -0.716543      -0.358055           -1.156855  \n",
              "4       -0.708685   -0.622235      -1.024614           -1.225219  \n",
              "...           ...         ...            ...                 ...  \n",
              "19995   -0.148144    0.281546      -1.417172            0.155051  \n",
              "19996    1.830551    1.405379      -0.253390            0.260627  \n",
              "19997   -0.647680   -0.732261      -0.832808           -1.255507  \n",
              "19998   -1.219716   -1.271910      -0.316431           -0.385807  \n",
              "19999   -0.594632   -0.627474       2.467258            2.534837  \n",
              "\n",
              "[20000 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f1d4fec8-d57a-4e87-96c7-7410d6c656ee\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.623352</td>\n",
              "      <td>-0.672591</td>\n",
              "      <td>-1.083095</td>\n",
              "      <td>1.366966</td>\n",
              "      <td>1.771168</td>\n",
              "      <td>-0.362989</td>\n",
              "      <td>-0.072107</td>\n",
              "      <td>-1.251624</td>\n",
              "      <td>-1.213104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.543496</td>\n",
              "      <td>-0.574283</td>\n",
              "      <td>-0.765186</td>\n",
              "      <td>2.303412</td>\n",
              "      <td>3.240388</td>\n",
              "      <td>-0.262197</td>\n",
              "      <td>-0.095684</td>\n",
              "      <td>-1.079867</td>\n",
              "      <td>-1.098875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.498578</td>\n",
              "      <td>-0.906658</td>\n",
              "      <td>-0.924141</td>\n",
              "      <td>-0.880871</td>\n",
              "      <td>-0.865347</td>\n",
              "      <td>-0.965969</td>\n",
              "      <td>-1.002085</td>\n",
              "      <td>-1.168851</td>\n",
              "      <td>-1.050414</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.493587</td>\n",
              "      <td>-0.930065</td>\n",
              "      <td>-1.162572</td>\n",
              "      <td>-0.522007</td>\n",
              "      <td>-0.477834</td>\n",
              "      <td>-0.805056</td>\n",
              "      <td>-0.716543</td>\n",
              "      <td>-0.358055</td>\n",
              "      <td>-1.156855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.493587</td>\n",
              "      <td>-0.962834</td>\n",
              "      <td>-0.685709</td>\n",
              "      <td>-0.543603</td>\n",
              "      <td>-0.503985</td>\n",
              "      <td>-0.708685</td>\n",
              "      <td>-0.622235</td>\n",
              "      <td>-1.024614</td>\n",
              "      <td>-1.225219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19995</th>\n",
              "      <td>-0.146649</td>\n",
              "      <td>-0.564920</td>\n",
              "      <td>-0.447278</td>\n",
              "      <td>-0.545441</td>\n",
              "      <td>0.247267</td>\n",
              "      <td>-0.148144</td>\n",
              "      <td>0.281546</td>\n",
              "      <td>-1.417172</td>\n",
              "      <td>0.155051</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19996</th>\n",
              "      <td>0.711802</td>\n",
              "      <td>-0.733449</td>\n",
              "      <td>-0.129369</td>\n",
              "      <td>1.203846</td>\n",
              "      <td>1.293314</td>\n",
              "      <td>1.830551</td>\n",
              "      <td>1.405379</td>\n",
              "      <td>-0.253390</td>\n",
              "      <td>0.260627</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19997</th>\n",
              "      <td>-0.066793</td>\n",
              "      <td>0.315171</td>\n",
              "      <td>-1.480481</td>\n",
              "      <td>-0.772430</td>\n",
              "      <td>-0.801158</td>\n",
              "      <td>-0.647680</td>\n",
              "      <td>-0.732261</td>\n",
              "      <td>-0.832808</td>\n",
              "      <td>-1.255507</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19998</th>\n",
              "      <td>1.220883</td>\n",
              "      <td>-0.714723</td>\n",
              "      <td>0.903834</td>\n",
              "      <td>-1.167594</td>\n",
              "      <td>-1.245728</td>\n",
              "      <td>-1.219716</td>\n",
              "      <td>-1.271910</td>\n",
              "      <td>-0.316431</td>\n",
              "      <td>-0.385807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19999</th>\n",
              "      <td>-0.031857</td>\n",
              "      <td>-0.564920</td>\n",
              "      <td>1.062789</td>\n",
              "      <td>-0.400701</td>\n",
              "      <td>-0.653760</td>\n",
              "      <td>-0.594632</td>\n",
              "      <td>-0.627474</td>\n",
              "      <td>2.467258</td>\n",
              "      <td>2.534837</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20000 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f1d4fec8-d57a-4e87-96c7-7410d6c656ee')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f1d4fec8-d57a-4e87-96c7-7410d6c656ee button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f1d4fec8-d57a-4e87-96c7-7410d6c656ee');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(housing_df.loc[housing_df[\"median_house_value\"].idxmax(), \"median_house_value\"]) # max median_house_value\n",
        "print(housing_df.loc[housing_df[\"median_house_value\"].idxmin(), \"median_house_value\"]) # min median_house_value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWeiWUCLASd1",
        "outputId": "e6dcb93d-9661-4592-cdf1-323bb7c08895"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.53483684816792\n",
            "-1.6622413519178973\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split Training(80%) and Testing(20%) Dataset"
      ],
      "metadata": {
        "id": "RKfz-lhDcS4j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split \n",
        "\n",
        "# random sample\n",
        "# to reproduce result, give random_state\n",
        "# housing_train_df, housing_test_df = train_test_split(housing_df, test_size=0.2, random_state=42)\n",
        "\n",
        "# order sample\n",
        "housing_train_df = housing_df.loc[:15999]\n",
        "housing_test_df = housing_df.loc[16000:]\n",
        "\n",
        "print(f\"Total {len(housing_df)}, Training: {len(housing_train_df)}, Testing: {len(housing_test_df)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mZv0Andaj2X",
        "outputId": "b93301e2-939b-4d9f-e9bc-667818405561"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total 20000, Training: 16000, Testing: 4000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialization"
      ],
      "metadata": {
        "id": "IaVvg8a4gvNb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HousingDataset(Dataset): # inherit Dataset\n",
        "\n",
        "  def __init__(self, dataframe):\n",
        "    self.dataframe = dataframe\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    row = self.dataframe.iloc[index].to_numpy().astype('float32') # using index to locate a data row\n",
        "    features = row[0:-1] # get all columns except last one\n",
        "    label = row[-1] # last column => we want to predict\n",
        "    return features, label\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.dataframe)"
      ],
      "metadata": {
        "id": "inWBLD-Fg_YD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "setup_seed(8888)\n",
        "\n",
        "train_dataset = HousingDataset(housing_train_df.astype('float32'))\n",
        "test_dataset = HousingDataset(housing_test_df.astype('float32'))\n",
        "train_dataloader = DataLoader(train_dataset, batch_size = len(housing_train_df), shuffle = True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size = len(housing_test_df), shuffle = True)"
      ],
      "metadata": {
        "id": "qPfRq1EjlTvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using {} device\".format(device))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHKo4Kwmlj-k",
        "outputId": "264b9ff8-e6e1-478e-8665-58fcbe5df940"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Two Layers NN model\n",
        "<img\n",
        "width=\"400px\"\n",
        "src=\"https://lh3.google.com/u/1/d/1XtrVTTKHxHkQNOpvzep27KpEymNAOY7I=w2992-h1654-iv2\"></img>"
      ],
      "metadata": {
        "id": "OHOh9llagxYK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TwoLayerNNModel(torch.nn.Module):\n",
        "\n",
        "  def __init__(self, D_in, H, D_out, activation_func, initial_weights = None):\n",
        "    super(TwoLayerNNModel, self).__init__()\n",
        "    self.linear1 = torch.nn.Linear(D_in, H) # FC1 (fully connected)\n",
        "    self.BatchNorm1 = torch.nn.BatchNorm1d(H) # BN1 (batch normalization)\n",
        "    self.linear2 = torch.nn.Linear(H, D_out)\n",
        "    \n",
        "    self.activation_func = activation_func\n",
        "    if activation_func == 'ReLU':\n",
        "      self.relu = torch.nn.ReLU()\n",
        "    if activation_func == 'Tanh':\n",
        "      self.tanh = torch.nn.Tanh()\n",
        "\n",
        "    self.initial_weights = initial_weights\n",
        "    if self.initial_weights == 'small random number':\n",
        "      # H = W * X + B ; X = D_in\n",
        "      self.linear1.weight = torch.nn.Parameter(0.01 * torch.FloatTensor(np.random.randn(H, D_in))) # transpose\n",
        "      self.linear2.weight = torch.nn.Parameter(0.01 * torch.FloatTensor(np.random.randn(D_out, H)))\n",
        "    \n",
        "    #the other two ways to initialize weight\n",
        "    if self.initial_weights == 'Xavier':\n",
        "      torch.nn.init.xavier_uniform_(self.linear1.weight)\n",
        "      torch.nn.init.xavier_uniform_(self.linear2.weight)\n",
        "    if self.initial_weights == 'Kaiming':\n",
        "      torch.nn.init.kaiming_uniform_(self.linear1.weight)\n",
        "      torch.nn.init.kaiming_uniform_(self.linear2.weight)\n",
        "  \n",
        "  # input -> FC1 -> BN1 -> ReLU -> FC2 -> output\n",
        "  def forward(self, x): # input\n",
        "    layer1 = self.linear1(x) # FC1\n",
        "    \n",
        "    batchnorm1 = self.BatchNorm1(layer1) # BN1\n",
        "\n",
        "    # activation\n",
        "    activation = None\n",
        "    if self.activation_func == 'ReLU':\n",
        "      activation = self.relu(batchnorm1)\n",
        "    if self.activation_func == 'Tanh':\n",
        "      activation = self.tanh(batchnorm1)\n",
        "    \n",
        "    pred = self.linear2(activation) # FC2\n",
        "    return pred"
      ],
      "metadata": {
        "id": "vHDzj_pRcx6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initial Model Settings"
      ],
      "metadata": {
        "id": "sDibE3mYDRqg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "D_in = len(housing_train_df.columns) - 1 # all features except the last one(label)\n",
        "D_out = 1 # predict the label(median_house_value)\n",
        "hidden_nodes = [5, 8, 11] # different numbers of hidden nodes. can choose what you want\n",
        "learning_rate = 1e-3 # init learning rate\n",
        "loss_fn = torch.nn.MSELoss().to(device) # loss function using Mean Square Error(MSE)"
      ],
      "metadata": {
        "id": "EIx1OvbN9nl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Weight_Tuning_LG_UA\n",
        "Learning Goal and Undesired Atractor\n",
        "\n",
        "<img\n",
        "width=\"800px\"\n",
        "src=\"https://lh3.google.com/u/1/d/1ixKGpLJgH1N9BNlaYO-OQadTsrVSzdA_=w2070-h1654-iv2\"></img>"
      ],
      "metadata": {
        "id": "pa0oBfCY-jHu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. c is for c_th input data\n",
        "2. epsilon is 0.9905 (tolerant loss) => LG\n",
        "3. initial learning rate is 0.001\n",
        "4. epsilon1 is 0.00001 (tolerant min of learning rate) => UA\n",
        "  * may be caused by local min, saddle point, etc.\n",
        "\n",
        "Note: As soon as you meet the loop(at first entery point), build and loop."
      ],
      "metadata": {
        "id": "5zKMX2KX_ugC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "setup_seed(8888)\n",
        "\n",
        "model_LG_UA = TwoLayerNNModel(D_in, hidden_nodes[1], D_out, 'Tanh', 'small random number').to(device)\n",
        "optimizer_LG_UA = torch.optim.Adam(model_LG_UA.parameters(), lr = learning_rate) # Use Adam optimizer\n",
        "\n",
        "# Adam => Adaptive Moment Estimation => optimized gradient based optimizer"
      ],
      "metadata": {
        "id": "8NYreTxv-yKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "jAGDo9WTjKjd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we set one batch = dataset size, so it gonna loop onece\n",
        "for batch, (X, y) in enumerate(train_dataloader):\n",
        "\n",
        "  t = 0\n",
        "  isLGSatisfied = False\n",
        "  isMeetUA = False\n",
        "  \n",
        "  epsilon = 0.9905\n",
        "  epsilon1 = 1e-5\n",
        "\n",
        "  # forward\n",
        "  print(f\"{t}th round: \")\n",
        "\n",
        "  print('initial forward operation: ')\n",
        "  pred = model_LG_UA(X.to(device))\n",
        "  loss = loss_fn(pred, y.to(device))\n",
        "  print('* total loss: ', loss.item())\n",
        "  print('-------------------------------------')\n",
        "  \n",
        "  # Store w first\n",
        "  original_param = {}\n",
        "  for param in model_LG_UA.parameters():\n",
        "    original_param[param] = param\n",
        "\n",
        "  # weight tuning\n",
        "  # loop1\n",
        "  while not isLGSatisfied:\n",
        "    t+=1\n",
        "    print(f\"{t}th round (now at LG): \")\n",
        "    print('check stopping criteria(LG): ')\n",
        "    \n",
        "    if loss.item() < epsilon:\n",
        "      print(\"LG OK!\")\n",
        "      isLGSatisfied = True\n",
        "      break\n",
        "\n",
        "    else:\n",
        "      print(\"LG not OK!\")\n",
        "     \n",
        "      # if put ouside the loop, need to retain graph\n",
        "      print('Backward: calculate direction')\n",
        "      loss.backward() # calculate direction\n",
        "\n",
        "      # loop2\n",
        "      while not isMeetUA:\n",
        "        print('weight adjustment')\n",
        "        optimizer_LG_UA.step()\n",
        "\n",
        "        print(\"Forward Operation\")\n",
        "        pred2 = model_LG_UA(X.to(device))\n",
        "        loss2 = loss_fn(pred2, y.to(device))\n",
        "\n",
        "        print(\"check if loss is less than the original one\")\n",
        "        \n",
        "        if loss2.item() < loss.item():\n",
        "          print(\"\\nloss becomes smaller!\")\n",
        "\n",
        "          print('lr = lr * 1.2')\n",
        "          optimizer_LG_UA.param_groups[0]['lr'] *= 1.2\n",
        "\n",
        "          print(f\"update loss: {loss2}\")\n",
        "          loss = loss2\n",
        "\n",
        "          print('-------------------------------------')\n",
        "\n",
        "          # clean gradient\n",
        "          optimizer_LG_UA.zero_grad()\n",
        "\n",
        "          break\n",
        "\n",
        "        else:\n",
        "          print(\"\\nloss becomes bigger!\")\n",
        "\n",
        "          t+=1\n",
        "          print(f\"\\n{t}th round (now at UA)\")\n",
        "          print(\"check stopping criteria(UA): \")\n",
        "          if optimizer_LG_UA.param_groups[0]['lr'] > epsilon1:\n",
        "            print(\"haven't met UA!\")\n",
        "\n",
        "            # restore w\n",
        "            print(\"restore w\")\n",
        "            for param in model_LG_UA.parameters():\n",
        "              param = original_param[param]\n",
        "\n",
        "            # step smaller\n",
        "            print('lr = lr * 0.7')\n",
        "            optimizer_LG_UA.param_groups[0]['lr'] *= 0.7 \n",
        "\n",
        "            print('-------------------------------------')\n",
        "\n",
        "            # clean gradient\n",
        "            optimizer_LG_UA.zero_grad()\n",
        "\n",
        "            continue\n",
        "            \n",
        "          else:\n",
        "            print(\"have met UA!\")\n",
        "            print('-------------------------------------')\n",
        "            isMeetUA = True\n",
        "          \n",
        "    if isMeetUA:\n",
        "      break\n",
        "\n",
        "  if isLGSatisfied == True:\n",
        "    print('\\n-------------------------------------')\n",
        "    print(\"Acceptable SLFN\")\n",
        "  else:\n",
        "    print('\\n-------------------------------------')\n",
        "    print(\"Unacceptable SLFN\")\n",
        "\n",
        "  print(f\"loss: {loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYQsuoC1jNsY",
        "outputId": "ac4d9e33-5df5-4915-f832-511e3424a6fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0th round: \n",
            "initial forward operation: \n",
            "* total loss:  0.9949537515640259\n",
            "-------------------------------------\n",
            "1th round (now at LG): \n",
            "check stopping criteria(LG): \n",
            "LG not OK!\n",
            "Backward: calculate direction\n",
            "weight adjustment\n",
            "Forward Operation\n",
            "check if loss is less than the original one\n",
            "\n",
            "loss becomes smaller!\n",
            "lr = lr * 1.2\n",
            "update loss: 0.9947198629379272\n",
            "-------------------------------------\n",
            "2th round (now at LG): \n",
            "check stopping criteria(LG): \n",
            "LG not OK!\n",
            "Backward: calculate direction\n",
            "weight adjustment\n",
            "Forward Operation\n",
            "check if loss is less than the original one\n",
            "\n",
            "loss becomes smaller!\n",
            "lr = lr * 1.2\n",
            "update loss: 0.9944754838943481\n",
            "-------------------------------------\n",
            "3th round (now at LG): \n",
            "check stopping criteria(LG): \n",
            "LG not OK!\n",
            "Backward: calculate direction\n",
            "weight adjustment\n",
            "Forward Operation\n",
            "check if loss is less than the original one\n",
            "\n",
            "loss becomes smaller!\n",
            "lr = lr * 1.2\n",
            "update loss: 0.994215190410614\n",
            "-------------------------------------\n",
            "4th round (now at LG): \n",
            "check stopping criteria(LG): \n",
            "LG not OK!\n",
            "Backward: calculate direction\n",
            "weight adjustment\n",
            "Forward Operation\n",
            "check if loss is less than the original one\n",
            "\n",
            "loss becomes smaller!\n",
            "lr = lr * 1.2\n",
            "update loss: 0.993943989276886\n",
            "-------------------------------------\n",
            "5th round (now at LG): \n",
            "check stopping criteria(LG): \n",
            "LG not OK!\n",
            "Backward: calculate direction\n",
            "weight adjustment\n",
            "Forward Operation\n",
            "check if loss is less than the original one\n",
            "\n",
            "loss becomes smaller!\n",
            "lr = lr * 1.2\n",
            "update loss: 0.9936684370040894\n",
            "-------------------------------------\n",
            "6th round (now at LG): \n",
            "check stopping criteria(LG): \n",
            "LG not OK!\n",
            "Backward: calculate direction\n",
            "weight adjustment\n",
            "Forward Operation\n",
            "check if loss is less than the original one\n",
            "\n",
            "loss becomes smaller!\n",
            "lr = lr * 1.2\n",
            "update loss: 0.9933728575706482\n",
            "-------------------------------------\n",
            "7th round (now at LG): \n",
            "check stopping criteria(LG): \n",
            "LG not OK!\n",
            "Backward: calculate direction\n",
            "weight adjustment\n",
            "Forward Operation\n",
            "check if loss is less than the original one\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([16000])) that is different to the input size (torch.Size([16000, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "loss becomes smaller!\n",
            "lr = lr * 1.2\n",
            "update loss: 0.9930391311645508\n",
            "-------------------------------------\n",
            "8th round (now at LG): \n",
            "check stopping criteria(LG): \n",
            "LG not OK!\n",
            "Backward: calculate direction\n",
            "weight adjustment\n",
            "Forward Operation\n",
            "check if loss is less than the original one\n",
            "\n",
            "loss becomes smaller!\n",
            "lr = lr * 1.2\n",
            "update loss: 0.9926501512527466\n",
            "-------------------------------------\n",
            "9th round (now at LG): \n",
            "check stopping criteria(LG): \n",
            "LG not OK!\n",
            "Backward: calculate direction\n",
            "weight adjustment\n",
            "Forward Operation\n",
            "check if loss is less than the original one\n",
            "\n",
            "loss becomes smaller!\n",
            "lr = lr * 1.2\n",
            "update loss: 0.9922142624855042\n",
            "-------------------------------------\n",
            "10th round (now at LG): \n",
            "check stopping criteria(LG): \n",
            "LG not OK!\n",
            "Backward: calculate direction\n",
            "weight adjustment\n",
            "Forward Operation\n",
            "check if loss is less than the original one\n",
            "\n",
            "loss becomes smaller!\n",
            "lr = lr * 1.2\n",
            "update loss: 0.9917640089988708\n",
            "-------------------------------------\n",
            "11th round (now at LG): \n",
            "check stopping criteria(LG): \n",
            "LG not OK!\n",
            "Backward: calculate direction\n",
            "weight adjustment\n",
            "Forward Operation\n",
            "check if loss is less than the original one\n",
            "\n",
            "loss becomes smaller!\n",
            "lr = lr * 1.2\n",
            "update loss: 0.9913185238838196\n",
            "-------------------------------------\n",
            "12th round (now at LG): \n",
            "check stopping criteria(LG): \n",
            "LG not OK!\n",
            "Backward: calculate direction\n",
            "weight adjustment\n",
            "Forward Operation\n",
            "check if loss is less than the original one\n",
            "\n",
            "loss becomes smaller!\n",
            "lr = lr * 1.2\n",
            "update loss: 0.9908888936042786\n",
            "-------------------------------------\n",
            "13th round (now at LG): \n",
            "check stopping criteria(LG): \n",
            "LG not OK!\n",
            "Backward: calculate direction\n",
            "weight adjustment\n",
            "Forward Operation\n",
            "check if loss is less than the original one\n",
            "\n",
            "loss becomes smaller!\n",
            "lr = lr * 1.2\n",
            "update loss: 0.990588366985321\n",
            "-------------------------------------\n",
            "14th round (now at LG): \n",
            "check stopping criteria(LG): \n",
            "LG not OK!\n",
            "Backward: calculate direction\n",
            "weight adjustment\n",
            "Forward Operation\n",
            "check if loss is less than the original one\n",
            "\n",
            "loss becomes smaller!\n",
            "lr = lr * 1.2\n",
            "update loss: 0.9904861450195312\n",
            "-------------------------------------\n",
            "15th round (now at LG): \n",
            "check stopping criteria(LG): \n",
            "LG OK!\n",
            "\n",
            "-------------------------------------\n",
            "Acceptable SLFN\n",
            "loss: 0.9904861450195312\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Weight_Tuning_EB_LG_UA\n",
        "Epoch Bound, Learning Goal and Undesired Atractor\n",
        "\n",
        "<img\n",
        "width=\"800px\"\n",
        "src=\"https://lh3.google.com/u/1/d/1qjI9MxwToHkw0k8t_pXCavMz8AGq10sz=w2070-h1654-iv2\"></img>"
      ],
      "metadata": {
        "id": "LT3jDthd16bv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "setup_seed(8888)\n",
        "epoch_bound = 50\n",
        "\n",
        "model_EB_LG_UA = TwoLayerNNModel(D_in, hidden_nodes[1], D_out, 'Tanh', 'small random number').to(device)\n",
        "optimizer_EB_LG_UA = torch.optim.Adam(model_LG_UA.parameters(), lr = learning_rate) "
      ],
      "metadata": {
        "id": "JXm8XlFx2Dwu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we set one batch = dataset size\n",
        "# so it gonna loop onece (every data => one epoch)\n",
        "for batch, (X, y) in enumerate(train_dataloader):\n",
        "\n",
        "  t = 0 \n",
        "  isLGSatisfied = False\n",
        "  isMeetUA = False\n",
        "  isMeetEpochBound = False\n",
        "  \n",
        "  epsilon = 0.9905\n",
        "  epsilon1 = 1e-5\n",
        "\n",
        "  # forward\n",
        "  print(f\"{t}th round: \")\n",
        "\n",
        "  print('initial forward operation: ')\n",
        "  pred = model_LG_UA(X.to(device))\n",
        "  loss = loss_fn(pred, y.to(device))\n",
        "  print('* total loss: ', loss.item())\n",
        "  print('-------------------------------------')\n",
        "  \n",
        "  # Store w first\n",
        "  original_param = {}\n",
        "  for param in model_LG_UA.parameters():\n",
        "    original_param[param] = param\n",
        "\n",
        "  # weight tuning\n",
        "  # loop1\n",
        "  while not isLGSatisfied:\n",
        "    print(f\"{t+1}th round (now at LG)\") # Cuz begining t = 0\n",
        "    print('check stopping criteria(LG): ')\n",
        "    \n",
        "    if loss.item() < epsilon:\n",
        "      print(\"LG OK!\")\n",
        "      isLGSatisfied = True\n",
        "      break\n",
        "\n",
        "    else:\n",
        "      print(\"LG not OK!\")\n",
        "     \n",
        "      # if put ouside the loop, need to retain graph\n",
        "      print('Backward: calculate direction')\n",
        "      loss.backward() # calculate direction\n",
        "\n",
        "      # loop2\n",
        "      while not isMeetUA:\n",
        "        print('weight adjustment')\n",
        "        optimizer_LG_UA.step()\n",
        "\n",
        "        print(\"Forward Operation\")\n",
        "        pred2 = model_LG_UA(X.to(device))\n",
        "        loss2 = loss_fn(pred2, y.to(device))\n",
        "\n",
        "        print(\"check if loss is less than the original one\")\n",
        "        \n",
        "        if loss2.item() < loss.item():\n",
        "          print(\"\\nloss becomes smaller!\")\n",
        "\n",
        "          print('lr = lr * 1.2')\n",
        "          optimizer_LG_UA.param_groups[0]['lr'] *= 1.2\n",
        "\n",
        "          print(f\"update loss: {loss2}\")\n",
        "          loss = loss2\n",
        "\n",
        "          # successfully weight tune once\n",
        "          t+=1\n",
        "          isMeetEpochBound = t == epoch_bound\n",
        "\n",
        "          if isMeetEpochBound:\n",
        "            print(\"Meet Epoch Bound!\")\n",
        "            break\n",
        "\n",
        "          print('-------------------------------------')\n",
        "\n",
        "          # clean gradient\n",
        "          optimizer_LG_UA.zero_grad()\n",
        "\n",
        "          break\n",
        "\n",
        "        else:\n",
        "          print(\"\\nloss becomes bigger!\")\n",
        "\n",
        "          print(f\"\\n{t}th round (now at UA)\")\n",
        "          print(\"check stopping criteria(UA): \")\n",
        "          if optimizer_LG_UA.param_groups[0]['lr'] > epsilon1:\n",
        "            print(\"haven't met UA!\")\n",
        "\n",
        "            # restore w\n",
        "            print(\"restore w\")\n",
        "            for param in model_LG_UA.parameters():\n",
        "              param = original_param[param]\n",
        "\n",
        "            # step smaller\n",
        "            print('lr = lr * 0.7')\n",
        "            optimizer_LG_UA.param_groups[0]['lr'] *= 0.7 \n",
        "\n",
        "            print('-------------------------------------')\n",
        "\n",
        "            # clean gradient\n",
        "            optimizer_LG_UA.zero_grad()\n",
        "\n",
        "            continue\n",
        "            \n",
        "          else:\n",
        "            print(\"have met UA!\")\n",
        "            print('-------------------------------------')\n",
        "            isMeetUA = True\n",
        "          \n",
        "    if isMeetUA:\n",
        "      break\n",
        "\n",
        "    if isMeetEpochBound:\n",
        "      break\n",
        "\n",
        "  if isLGSatisfied == True:\n",
        "    print('\\n-------------------------------------')\n",
        "    print(\"Acceptable SLFN\")\n",
        "  else:\n",
        "    print('\\n-------------------------------------')\n",
        "    print(\"Unacceptable SLFN\")\n",
        "\n",
        "  print(f\"loss: {loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xl-SR57OicmL",
        "outputId": "45fd453d-e841-4862-ead4-277c0d5ff789"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0th round: \n",
            "initial forward operation: \n",
            "* total loss:  0.9904861450195312\n",
            "-------------------------------------\n",
            "1th round (now at LG)\n",
            "check stopping criteria(LG): \n",
            "LG OK!\n",
            "\n",
            "-------------------------------------\n",
            "Acceptable SLFN\n",
            "loss: 0.9904861450195312\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Export Model\n",
        "* .pt \n",
        "  * save the state of pytorch model (including parameters)\n",
        "  * can load later and train\n",
        "\n",
        "* .pth\n",
        "  * store pre-trained model weights that can be loaded into a PyTorch model\n",
        "  * fine-tune the model on your own dataset"
      ],
      "metadata": {
        "id": "Z1m9OD4Piedl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model_LG_UA, 'model_LG_UA.pt')\n",
        "torch.save(model_EB_LG_UA, 'model_EB_LG_UA.pt')"
      ],
      "metadata": {
        "id": "skPOgyStifwk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}